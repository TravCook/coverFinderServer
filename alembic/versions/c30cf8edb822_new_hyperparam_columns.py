"""new_hyperparam_columns

Revision ID: c30cf8edb822
Revises: 8208ae2f56ef
Create Date: 2025-11-08 09:30:07.469531

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'c30cf8edb822'
down_revision: Union[str, Sequence[str], None] = '8208ae2f56ef'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('HyperParams', sa.Column('regression_estimators', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_learning_rate', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_max_depth', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_subsample', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_colsample_bytree', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_colsample_bylevel', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_colsample_bynode', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_reg_alpha', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('regression_reg_lambda', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_estimators', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_learning_rate', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_max_depth', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_subsample', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_colsample_bytree', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_colsample_bylevel', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_colsample_bynode', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_reg_alpha', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('classification_reg_lambda', sa.Float(), nullable=True))
    op.drop_column('HyperParams', 'bestAccuracy')
    op.drop_column('HyperParams', 'epochs')
    op.drop_column('HyperParams', 'scoreLoss')
    op.drop_column('HyperParams', 'earlyStopPatience')
    op.drop_column('HyperParams', 'hiddenLayers')
    op.drop_column('HyperParams', 'historyLength')
    op.drop_column('HyperParams', 'spreadMAE')
    op.drop_column('HyperParams', 'kFolds')
    op.drop_column('HyperParams', 'learningRate')
    op.drop_column('HyperParams', 'totalMAE')
    op.drop_column('HyperParams', 'scoreMAE')
    op.drop_column('HyperParams', 'dropoutReg')
    op.drop_column('HyperParams', 'decayFactor')
    op.drop_column('HyperParams', 'l2Reg')
    op.drop_column('HyperParams', 'gameDecayThreshold')
    op.drop_column('HyperParams', 'batchSize')
    op.drop_column('HyperParams', 'winPctLoss')
    op.drop_column('HyperParams', 'layerNeurons')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('HyperParams', sa.Column('layerNeurons', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('winPctLoss', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'1'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('batchSize', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('gameDecayThreshold', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('l2Reg', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('decayFactor', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('dropoutReg', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('scoreMAE', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('totalMAE', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('learningRate', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('kFolds', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('spreadMAE', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('historyLength', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('hiddenLayers', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('earlyStopPatience', sa.INTEGER(), server_default=sa.text('10'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('scoreLoss', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'1'::double precision"), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('epochs', sa.INTEGER(), server_default=sa.text('0'), autoincrement=False, nullable=False))
    op.add_column('HyperParams', sa.Column('bestAccuracy', sa.DOUBLE_PRECISION(precision=53), server_default=sa.text("'0'::double precision"), autoincrement=False, nullable=False))
    op.drop_column('HyperParams', 'classification_reg_lambda')
    op.drop_column('HyperParams', 'classification_reg_alpha')
    op.drop_column('HyperParams', 'classification_colsample_bynode')
    op.drop_column('HyperParams', 'classification_colsample_bylevel')
    op.drop_column('HyperParams', 'classification_colsample_bytree')
    op.drop_column('HyperParams', 'classification_subsample')
    op.drop_column('HyperParams', 'classification_max_depth')
    op.drop_column('HyperParams', 'classification_learning_rate')
    op.drop_column('HyperParams', 'classification_estimators')
    op.drop_column('HyperParams', 'regression_reg_lambda')
    op.drop_column('HyperParams', 'regression_reg_alpha')
    op.drop_column('HyperParams', 'regression_colsample_bynode')
    op.drop_column('HyperParams', 'regression_colsample_bylevel')
    op.drop_column('HyperParams', 'regression_colsample_bytree')
    op.drop_column('HyperParams', 'regression_subsample')
    op.drop_column('HyperParams', 'regression_max_depth')
    op.drop_column('HyperParams', 'regression_learning_rate')
    op.drop_column('HyperParams', 'regression_estimators')
    # ### end Alembic commands ###
