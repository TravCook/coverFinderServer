"""changing_hyper_params2

Revision ID: dbb4246e22ca
Revises: 506a02a3439c
Create Date: 2025-11-26 14:52:32.290450

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision: str = 'dbb4246e22ca'
down_revision: Union[str, Sequence[str], None] = '506a02a3439c'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('HyperParams', sa.Column('xgb_estimators', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_learning_rate', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_max_depth', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_subsample', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_colsample_bytree', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_reg_alpha', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_reg_lambda', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('xgb_min_child_weight', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_num_leaves', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_learning_rate', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_feature_fraction', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_bagging_fraction', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_bagging_freq', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_min_data_in_leaf', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_lambda_l1', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_lambda_l2', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('lgb_n_estimators', sa.Integer(), nullable=True))
    op.add_column('HyperParams', sa.Column('cb_depth', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('cb_learning_rate', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('cb_l2_leaf_reg', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('cb_bagging_temperature', sa.Float(), nullable=True))
    op.add_column('HyperParams', sa.Column('cb_iterations', sa.Integer(), nullable=True))
    op.drop_column('HyperParams', 'regression_max_depth')
    op.drop_column('HyperParams', 'regression_colsample_bytree')
    op.drop_column('HyperParams', 'regression_learning_rate')
    op.drop_column('HyperParams', 'regression_min_child_weight')
    op.drop_column('HyperParams', 'regression_estimators')
    op.drop_column('HyperParams', 'regression_subsample')
    op.drop_column('HyperParams', 'classification_reg_lambda')
    op.drop_column('HyperParams', 'classification_colsample_bytree')
    op.drop_column('HyperParams', 'classification_min_child_weight')
    op.drop_column('HyperParams', 'regression_reg_lambda')
    op.drop_column('HyperParams', 'classification_max_depth')
    op.drop_column('HyperParams', 'classification_estimators')
    op.drop_column('HyperParams', 'classification_reg_alpha')
    op.drop_column('HyperParams', 'classification_subsample')
    op.drop_column('HyperParams', 'regression_reg_alpha')
    op.drop_column('HyperParams', 'classification_learning_rate')
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('HyperParams', sa.Column('classification_learning_rate', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_reg_alpha', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_subsample', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_reg_alpha', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_estimators', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_max_depth', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_reg_lambda', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_min_child_weight', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_colsample_bytree', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('classification_reg_lambda', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_subsample', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_estimators', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_min_child_weight', sa.INTEGER(), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_learning_rate', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_colsample_bytree', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
    op.add_column('HyperParams', sa.Column('regression_max_depth', sa.INTEGER(), autoincrement=False, nullable=True))
    op.drop_column('HyperParams', 'cb_iterations')
    op.drop_column('HyperParams', 'cb_bagging_temperature')
    op.drop_column('HyperParams', 'cb_l2_leaf_reg')
    op.drop_column('HyperParams', 'cb_learning_rate')
    op.drop_column('HyperParams', 'cb_depth')
    op.drop_column('HyperParams', 'lgb_n_estimators')
    op.drop_column('HyperParams', 'lgb_lambda_l2')
    op.drop_column('HyperParams', 'lgb_lambda_l1')
    op.drop_column('HyperParams', 'lgb_min_data_in_leaf')
    op.drop_column('HyperParams', 'lgb_bagging_freq')
    op.drop_column('HyperParams', 'lgb_bagging_fraction')
    op.drop_column('HyperParams', 'lgb_feature_fraction')
    op.drop_column('HyperParams', 'lgb_learning_rate')
    op.drop_column('HyperParams', 'lgb_num_leaves')
    op.drop_column('HyperParams', 'xgb_min_child_weight')
    op.drop_column('HyperParams', 'xgb_reg_lambda')
    op.drop_column('HyperParams', 'xgb_reg_alpha')
    op.drop_column('HyperParams', 'xgb_colsample_bytree')
    op.drop_column('HyperParams', 'xgb_subsample')
    op.drop_column('HyperParams', 'xgb_max_depth')
    op.drop_column('HyperParams', 'xgb_learning_rate')
    op.drop_column('HyperParams', 'xgb_estimators')
    # ### end Alembic commands ###
